{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WjDdziEN_VCt"
   },
   "source": [
    "# 6강) FAISS 실습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1NWluWk3_VCu"
   },
   "source": [
    "### Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9095,
     "status": "ok",
     "timestamp": 1616878500274,
     "user": {
      "displayName": "JinUk Cho",
      "photoUrl": "",
      "userId": "10000090644219567406"
     },
     "user_tz": 420
    },
    "id": "eGqFS4EEBF_Z",
    "outputId": "7fb34e82-e0aa-47bb-d03f-9c73af1c34c4"
   },
   "outputs": [],
   "source": [
    "# !pip install datasets\n",
    "# !pip install transformers\n",
    "# !pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CYUkp06Y_VCv"
   },
   "source": [
    "## 5강의 자료를 활용해 passage / question enocoder 학습\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 9089,
     "status": "ok",
     "timestamp": 1616878500275,
     "user": {
      "displayName": "JinUk Cho",
      "photoUrl": "",
      "userId": "10000090644219567406"
     },
     "user_tz": 420
    },
    "id": "4IUxepuj_VCv"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "import random\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import BertModel, BertPreTrainedModel, AdamW, TrainingArguments, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import (DataLoader, RandomSampler, TensorDataset, SequentialSampler)\n",
    " \n",
    "torch.manual_seed(2021)\n",
    "torch.cuda.manual_seed(2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14939,
     "status": "ok",
     "timestamp": 1616878506128,
     "user": {
      "displayName": "JinUk Cho",
      "photoUrl": "",
      "userId": "10000090644219567406"
     },
     "user_tz": 420
    },
    "id": "AoB8BHGDmVIK",
    "outputId": "b98f643e-5434-4de9-b5e4-95b8a451d901"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset squad_kor_v1 (/opt/ml/.cache/huggingface/datasets/squad_kor_v1/squad_kor_v1/1.0.0/31982418accc53b059af090befa81e68880acc667ca5405d30ce6fa7910950a7)\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"squad_kor_v1\")\n",
    "corpus = list(set([example['context'] for example in dataset['train']]))\n",
    "len(corpus)\n",
    " \n",
    "model_checkpoint = \"bert-base-multilingual-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LeDo5VmOQ9hL"
   },
   "source": [
    "Training Dataset 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 14934,
     "status": "ok",
     "timestamp": 1616878506129,
     "user": {
      "displayName": "JinUk Cho",
      "photoUrl": "",
      "userId": "10000090644219567406"
     },
     "user_tz": 420
    },
    "id": "E_FQ1kcazxge"
   },
   "outputs": [],
   "source": [
    "# Use subset (128 examples) of original training dataset \n",
    "sample_idx = np.random.choice(range(len(dataset['train'])), 128)\n",
    "training_dataset = dataset['train'][sample_idx]\n",
    "\n",
    "q_seqs = tokenizer(training_dataset['question'], padding=\"max_length\", truncation=True, return_tensors='pt')\n",
    "p_seqs = tokenizer(training_dataset['context'], padding=\"max_length\", truncation=True, return_tensors='pt')\n",
    "\n",
    "train_dataset = TensorDataset(p_seqs['input_ids'], p_seqs['attention_mask'], p_seqs['token_type_ids'], \n",
    "                        q_seqs['input_ids'], q_seqs['attention_mask'], q_seqs['token_type_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JwMvVH1e3h99"
   },
   "source": [
    "BERT encoder 학습시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 14931,
     "status": "ok",
     "timestamp": 1616878506130,
     "user": {
      "displayName": "JinUk Cho",
      "photoUrl": "",
      "userId": "10000090644219567406"
     },
     "user_tz": 420
    },
    "id": "oKKkTlh_l5VL"
   },
   "outputs": [],
   "source": [
    "class BertEncoder(BertPreTrainedModel):\n",
    "  def __init__(self, config):\n",
    "    super(BertEncoder, self).__init__(config)\n",
    " \n",
    "    self.bert = BertModel(config)\n",
    "    self.init_weights()\n",
    "      \n",
    "  def forward(self, input_ids, \n",
    "              attention_mask=None, token_type_ids=None): \n",
    "  \n",
    "      outputs = self.bert(input_ids,\n",
    "                          attention_mask=attention_mask,\n",
    "                          token_type_ids=token_type_ids)\n",
    "      \n",
    "      pooled_output = outputs[1]\n",
    " \n",
    "      return pooled_output\n",
    " \n",
    " \n",
    "def train(args, dataset, p_model, q_model):\n",
    "  \n",
    "  # Dataloader\n",
    "  train_sampler = RandomSampler(dataset)\n",
    "  train_dataloader = DataLoader(dataset, sampler=train_sampler, batch_size=args.per_device_train_batch_size)\n",
    " \n",
    "  # Optimizer\n",
    "  no_decay = ['bias', 'LayerNorm.weight']\n",
    "  optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in p_model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': args.weight_decay},\n",
    "        {'params': [p for n, p in p_model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0},\n",
    "        {'params': [p for n, p in q_model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': args.weight_decay},\n",
    "        {'params': [p for n, p in q_model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "        ]\n",
    "  optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate, eps=args.adam_epsilon)\n",
    "  t_total = len(train_dataloader) // args.gradient_accumulation_steps * args.num_train_epochs\n",
    "  scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=args.warmup_steps, num_training_steps=t_total)\n",
    " \n",
    "  # Start training!\n",
    "  global_step = 0\n",
    "  \n",
    "  p_model.zero_grad()\n",
    "  q_model.zero_grad()\n",
    "  torch.cuda.empty_cache()\n",
    "  \n",
    "  train_iterator = trange(int(args.num_train_epochs), desc=\"Epoch\")\n",
    " \n",
    "  for _ in train_iterator:\n",
    "    epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\")\n",
    " \n",
    "    for step, batch in enumerate(epoch_iterator):\n",
    "      q_encoder.train()\n",
    "      p_encoder.train()\n",
    "      \n",
    "      if torch.cuda.is_available():\n",
    "        batch = tuple(t.cuda() for t in batch)\n",
    " \n",
    "      p_inputs = {'input_ids': batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'token_type_ids': batch[2]\n",
    "                  }\n",
    "      \n",
    "      q_inputs = {'input_ids': batch[3],\n",
    "                  'attention_mask': batch[4],\n",
    "                  'token_type_ids': batch[5]}\n",
    "      \n",
    "      p_outputs = p_model(**p_inputs)  # (batch_size, emb_dim)\n",
    "      q_outputs = q_model(**q_inputs)  # (batch_size, emb_dim)\n",
    " \n",
    " \n",
    "      # Calculate similarity score & loss\n",
    "      sim_scores = torch.matmul(q_outputs, torch.transpose(p_outputs, 0, 1))  # (batch_size, emb_dim) x (emb_dim, batch_size) = (batch_size, batch_size)\n",
    " \n",
    "      # target: position of positive samples = diagonal element \n",
    "      targets = torch.arange(0, args.per_device_train_batch_size).long()\n",
    "      if torch.cuda.is_available():\n",
    "        targets = targets.to('cuda')\n",
    " \n",
    "      sim_scores = F.log_softmax(sim_scores, dim=1)\n",
    " \n",
    "      loss = F.nll_loss(sim_scores, targets)\n",
    "      print(loss)\n",
    " \n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      scheduler.step()\n",
    "      q_model.zero_grad()\n",
    "      p_model.zero_grad()\n",
    "      global_step += 1\n",
    "      \n",
    "      torch.cuda.empty_cache()\n",
    " \n",
    " \n",
    "    \n",
    "  return p_model, q_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 14928,
     "status": "ok",
     "timestamp": 1616878506130,
     "user": {
      "displayName": "JinUk Cho",
      "photoUrl": "",
      "userId": "10000090644219567406"
     },
     "user_tz": 420
    },
    "id": "2NpTT64KRZTZ"
   },
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=\"dense_retireval\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27221,
     "status": "ok",
     "timestamp": 1616878518425,
     "user": {
      "displayName": "JinUk Cho",
      "photoUrl": "",
      "userId": "10000090644219567406"
     },
     "user_tz": 420
    },
    "id": "wnO1b30SomBP",
    "outputId": "cc6b4548-1fc0-434f-a6d0-f289cf01a9bd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertEncoder: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertEncoder: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# load pre-trained model on cuda (if available)\n",
    "p_encoder = BertEncoder.from_pretrained(model_checkpoint)\n",
    "q_encoder = BertEncoder.from_pretrained(model_checkpoint)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  p_encoder.cuda()\n",
    "  q_encoder.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f3Dgo8U997HD"
   },
   "source": [
    "Train function 정의 후, 두개의 encoder fine-tuning 하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 75650,
     "status": "ok",
     "timestamp": 1616878566858,
     "user": {
      "displayName": "JinUk Cho",
      "photoUrl": "",
      "userId": "10000090644219567406"
     },
     "user_tz": 420
    },
    "id": "E8a7ww3WgsaZ",
    "outputId": "6ed55f7d-371a-4ee3-96b4-fff0d937c7cb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(15.6777, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(21.0619, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(15.4835, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(16.6192, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.7702, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.1291, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.5531, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.9961, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3761, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2232, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.8770, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.9111, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.7991, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.1952, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.6506, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.7861, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.5539, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.8844, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5318, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.1349, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6211, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.7590, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.8947, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.2544, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.4644, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.7685, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.4179, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.8423, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.4916, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.9946, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.1310, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2367, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 32/32 [00:14<00:00,  2.19it/s]\n",
      "Epoch:  50%|█████     | 1/2 [00:14<00:14, 14.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.4735, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3806, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.1159, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3132, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2529, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3733, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1954, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2198, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.8727, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6007, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1532, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.7187, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6815, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9465, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.4855, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3244, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2707, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6030, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3724, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.5629, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2292, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.4725, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2325, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.8345, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.4403, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.9112, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6486, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3925, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3120, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.4990, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.8421, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5728, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 32/32 [00:14<00:00,  2.25it/s]\n",
      "Epoch: 100%|██████████| 2/2 [00:28<00:00, 14.42s/it]\n"
     ]
    }
   ],
   "source": [
    "p_encoder, q_encoder = train(args, train_dataset, p_encoder, q_encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "255WXyL_R8C4"
   },
   "source": [
    "## Passage retrieval 준비하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hWfVZoLcSmOY"
   },
   "source": [
    "Search corpus: KorQuAD validation context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 76202,
     "status": "ok",
     "timestamp": 1616878567413,
     "user": {
      "displayName": "JinUk Cho",
      "photoUrl": "",
      "userId": "10000090644219567406"
     },
     "user_tz": 420
    },
    "id": "WuP_PixqSllE",
    "outputId": "9d35e907-3f9d-4c3a-b191-a0a3a67404b5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "960"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_corpus = list(set([example['context'] for example in dataset['validation']]))\n",
    "len(search_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D2y8jFLnS-N5"
   },
   "source": [
    "Passage encoder를 활용하여 passage dense embedding 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 94638,
     "status": "ok",
     "timestamp": 1616878585853,
     "user": {
      "displayName": "JinUk Cho",
      "photoUrl": "",
      "userId": "10000090644219567406"
     },
     "user_tz": 420
    },
    "id": "5gc7iXXaSLtn",
    "outputId": "55272794-5ab0-44b4-d41b-46e471b673cb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 120/120 [00:10<00:00, 11.98it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(960, 768)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_batch_size = 8\n",
    "\n",
    "# Construt dataloader\n",
    "valid_p_seqs = tokenizer(search_corpus, padding=\"max_length\", truncation=True, return_tensors='pt')\n",
    "valid_dataset = TensorDataset(valid_p_seqs['input_ids'], valid_p_seqs['attention_mask'], valid_p_seqs['token_type_ids'])\n",
    "valid_sampler = SequentialSampler(valid_dataset)\n",
    "valid_dataloader = DataLoader(valid_dataset, sampler=valid_sampler, batch_size=eval_batch_size)\n",
    "\n",
    "# Inference using the passage encoder to get dense embeddeings\n",
    "p_embs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "  epoch_iterator = tqdm(valid_dataloader, desc=\"Iteration\", position=0, leave=True)\n",
    "  p_encoder.eval()\n",
    "\n",
    "  for _, batch in enumerate(epoch_iterator):\n",
    "    batch = tuple(t.cuda() for t in batch)\n",
    "\n",
    "    p_inputs = {'input_ids': batch[0],\n",
    "                'attention_mask': batch[1],\n",
    "                'token_type_ids': batch[2]\n",
    "                }\n",
    "        \n",
    "    outputs = p_encoder(**p_inputs).to('cpu').numpy()\n",
    "    p_embs.extend(outputs)\n",
    "\n",
    "p_embs = np.array(p_embs)\n",
    "p_embs.shape  # (num_passage, emb_dim)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8zBkp_wzg0fi"
   },
   "source": [
    "Question encoder를 활용해여 quesntion dense embedding 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 94635,
     "status": "ok",
     "timestamp": 1616878585853,
     "user": {
      "displayName": "JinUk Cho",
      "photoUrl": "",
      "userId": "10000090644219567406"
     },
     "user_tz": 420
    },
    "id": "WmteKZRVfcAn",
    "outputId": "d6368661-deff-431e-abbb-23e0ab7e5933"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['대한민국 제14대 대통령으로 향년 89세를 일기로 서거한 김영삼 대통령의 묘소가 있는 곳은?',\n",
       " '금강산의 겨울 이름은?',\n",
       " '유관순 열사는 당시 어떤 종교를 믿고 있었는가?',\n",
       " '1997년 10월 23일, 국회 본회의 대표 연설에서 전두환, 노태우 전 대통령에 대한 사면을 촉구한 새정치 국민회의 의원은?',\n",
       " '셰르징거가 찾아왔다가 우연히 푸시캣 돌스에 영입된 곳은?']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "sample_idx = np.random.choice(range(len(dataset['validation'])), 5)\n",
    "query = dataset['validation'][sample_idx]['question']\n",
    "ground_truth = dataset['validation'][sample_idx]['context']\n",
    "\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 94632,
     "status": "ok",
     "timestamp": 1616878585854,
     "user": {
      "displayName": "JinUk Cho",
      "photoUrl": "",
      "userId": "10000090644219567406"
     },
     "user_tz": 420
    },
    "id": "68khtz4ziZSF",
    "outputId": "3b999c1c-f2ed-4ed6-e95b-eb0bd178e7eb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 768)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_q_seqs = tokenizer(query, padding=\"max_length\", truncation=True, return_tensors='pt').to('cuda')\n",
    "\n",
    "with torch.no_grad():\n",
    "  q_encoder.eval()\n",
    "  q_embs = q_encoder(**valid_q_seqs).to('cpu').numpy()\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "q_embs.shape  # (num_query, emb_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "owo71hnTSGnN"
   },
   "source": [
    "## GPU를 활용하여 passage retrieval 수행하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iKrsJ3jOjDpf"
   },
   "source": [
    "GPU에서 exhaustive search 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 94629,
     "status": "ok",
     "timestamp": 1616878585854,
     "user": {
      "displayName": "JinUk Cho",
      "photoUrl": "",
      "userId": "10000090644219567406"
     },
     "user_tz": 420
    },
    "id": "PUI0hmYaSBwS"
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "  p_embs_cuda = torch.Tensor(p_embs).to('cuda')\n",
    "  q_embs_cuda = torch.Tensor(q_embs).to('cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 94627,
     "status": "ok",
     "timestamp": 1616878585854,
     "user": {
      "displayName": "JinUk Cho",
      "photoUrl": "",
      "userId": "10000090644219567406"
     },
     "user_tz": 420
    },
    "id": "_menV6jNjM40",
    "outputId": "d9bc0c61-cf2c-423f-b1b2-fedbc90b1668"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[231, 252, 268,  ..., 931, 938, 390],\n",
      "        [231, 252, 946,  ..., 196, 390, 876],\n",
      "        [404, 438, 515,  ...,  40, 898, 587],\n",
      "        [785, 621, 200,  ..., 956, 469, 144],\n",
      "        [231, 411, 301,  ..., 545, 390, 938]], device='cuda:0')\n",
      "--- 0.0023641586303710938 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "dot_prod_scores = torch.matmul(q_embs_cuda, torch.transpose(p_embs_cuda, 0, 1))\n",
    "\n",
    "rank = torch.argsort(dot_prod_scores, dim=1, descending=True).squeeze()\n",
    "print(rank)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 94625,
     "status": "ok",
     "timestamp": 1616878585855,
     "user": {
      "displayName": "JinUk Cho",
      "photoUrl": "",
      "userId": "10000090644219567406"
     },
     "user_tz": 420
    },
    "id": "fGbwk2FjoIUm",
    "outputId": "cf6a565d-8557-49b9-bff9-c5dd41f543a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Search query]\n",
      " 대한민국 제14대 대통령으로 향년 89세를 일기로 서거한 김영삼 대통령의 묘소가 있는 곳은? \n",
      "\n",
      "[Ground truth passage]\n",
      "2015년 11월 10일 건강검진 차 서울대학교 병원을 찾아 17일까지 입원한 뒤 퇴원했다. 그러다, 이틀 뒤인 19일 고열과 혈액감염 의심 증세로 서울대학교 병원에 다시 입원한 후, 11월 21일 오후에 증세가 급격히 악화됨에 따라 중환자실로 옮겨졌다. 상태가 전혀 호전되지 않던 김영삼은 결국 2015년 11월 22일 오전 0시 21분 32초에 병마를 물리치지 못하고 혈액 감염 의심으로 치료를 받던 중 향년 89세의 일기로 서거하였다. 사망에 이른 직접적인 원인은 허약한 전신 상태에 패혈증과 급성 심부전이 겹쳐 일어난 것으로 판단되었다. 장례는 대한민국 최초로 5일간 국가장으로 치뤄졌다. 이는 국장과 국민장이 통합된 이후 처음 치뤄지는 국가장이다. 이어 11월 26일 국회의사당에서 영결식이 있었고 국립서울현충원에 안장되었다. 묘소의 정확한 위치는 제3장군묘역 우측능선에 위치하고 있으며 단독 묘역이다. \n",
      "\n",
      "Top-1 passage with score 23.2187\n",
      "2011년 10월 15일, 10.26 서울시장 보궐선거에 나선 한나라당 나경원 후보가 자신의 트위터에서 스스로를 지지하는 ‘자화자찬’하는 글을 올려 논란이 일었다. 자신이 작성한 글을 리트윗(재인용)해 “콘텐츠가 있는 공약과 정책 정말 멋집니다” 등 자신을 지지하는 댓글을 달았다. 이에 네티즌들이 ‘나르시즘 나경원’ ‘자화자찬도 유분수’ ‘알바의 실수인가’ 등의 지적을 하자 나경원 측은 2011년 10월 16일 해당 트위터 글을 삭제하고 “확인 결과 시스템 간에 충돌이 일어나 계정 연동 오류가 발생한 것으로 확인됐다”며 “현재 오류를 바로 잡았다”고 밝혔다. 그러나 2011년 10월 20일 한 트위터 사용자가 나경원 트위터 멘션 오류에 대해 트위터 본사에 문의한 내용을 온라인에 게시했는데 트위터 본사 답변에 따르면 “나 후보 측의 트위터 글은 트위터 내부 오류나 장애가 아니다”라며 “후보자는 트윗을 포스팅 하기 위해 외부 어플리케이션을 사용한 것으로 보인다”고 답했다. 이어 “이같은 오류나 장애는 트위터가 아닌 이 어플리케이션에서 발생된 것으로 보인다”며 트위터 계정 연동 오류가 아니라고 밝혀 '계정 연동 시스템 오류'라던 나경원의 해명이 거짓말로 드러났다.\n",
      "Top-2 passage with score 23.0836\n",
      "한편 대한민국 내 방송사로는 유일하게 SBS에서 단독으로 밴쿠버 올림픽 개·폐회식 및 경기 등을 생중계하였다. SBS를 제외한 나머지 지상파 방송사들은 아예 밴쿠버 현지에 취재진 등을 파견하거나 올림픽에 관한 방송을 하지 않기로 방침을 정했으나, 시청자들의 항의로 SBS에서 제공한 2분분량의 영상으로 관련보도를 하는데 합의하였다. SBS는 IOC와의 올림픽 중계 독점계약 절차에 따라 향후 2012년 영국 런던과 2016년 브라질 리우데자네이루에서 개최되는 하계 올림픽과 2014년 러시아 소치에서 열리는 동계 올림픽에서도 올림픽 단독중계를 하게 될 예정이었다. 이에 KBS와 MBC 등 방송사들이 방송통신위원회에 공동 중계요청을 제안했으나 SBS측이 IOC와의 독점계약상에 위반된다는 이유로 이를 거부하여 결국 SBS 단독으로 올림픽 중계를 하게 되었다. 그러나 방송통신위원회의 징계로 SBS가 과징금을 물게 되어 2012년 영국 런던과 2016년 브라질 리우데자네이루에서 개최되는 하계 올림픽과 2014년 러시아 소치에서 열리는 동계 올림픽 부터 독점중계를 깨고 지상파 3사가 공동 중계하게 되었다. 한편 SBS는 올림픽 생중계 도중 스피드 스케이팅 중계 때 대한민국의 박도영 선수를 소개하는 자막에서 태극기와 대한민국(KOR)이 아닌 일본의 일장기와 일본(JPN) 국적으로 오표기를 하여 논란을 일으키기도 했다. 이에 SBS 게시판에는 항의의 글들이 쇄도했으며 SBS는 이에 대해 공식적으로 사과와 해명을 하였다.\n",
      "Top-3 passage with score 22.9450\n",
      "가상화폐(virtual currency)에 관한 정의를 살펴보면 다음과 같다. 유럽중앙은행(ECB)은 2012년에 가상화폐를 “개발자에 의하여 발행되고 통상 관리되며, 특정한 가상커뮤니티의 회원들 간에 사용되고 수령되는 규제되지 않은 디지털화폐의 한 유형”이라고 정의하였다. 2012년 유럽중앙은행(European Central Bank)은 가상화폐란 “중앙은행에 의하여 발행되거나 보장되지 않고 지급수단으로 기능하는 규제되지 않은 디지털화폐의 한 유형”이라고 하였다. 또 2014년 “중앙은행이나 공적 기관이 발행하지 않고 반드시 법령에 의한 화폐(fiat currency)에 속하지도 않지만, 자연인 또는 법인에 의하여 지급수단으로 수령되고 전자적으로 양도·저장 또는 거래될 수 있는 가치의 전자적 표시”라고 하였다. 2013년 미국 재무부 금융범죄규제망(FinCEN)은 화폐(currency)를 “법화(法貨, legal tender)로 지정되어 발행국가의 교환수단으로 유통되고 통상 사용·수령되는 동전과 지폐”라고 정의하고, 이러한 진정한 화폐에 대하여 \"가상”화폐(“virtual” currency)란 “어떤 환경에서는 법화인 화폐처럼 작동하지만 진정한 화폐의 속성을 가지고 있지 않은 교환수단”으로서, 어떠한 관할권에서도 법화의 지위를 가지지 않는다고 한다. 유럽중앙은행(ECB), 유럽은행감독청(EBA), 미국 재무부에서 내린 정의에 따르면, 가상화폐란 정부에 의해 통제 받지 않는 디지털화폐의 일종으로 개발자가 발행·관리하며 특정한 가상 커뮤니티에서만 통용되는 결제수단이다. 미국 재무부 금융범죄규제망(FinCEN)은 전자상품권 등을 제외하고 비트코인·이더리움·리플 등 암호화폐를 가리킬 때는 가상화폐라는 단어를 쓰지 않는다.\n",
      "Top-4 passage with score 22.9405\n",
      "그가 중학교 2학년 때, 친척에게 물려받은 클래식 기타로 연주연습을 하면서 음악에 흥미를 느끼기 시작했다. 충암고등학교에 진학한 후에는 같은 반 친구인 김학인과 함께 스쿨 밴드인 ‘페이퍼 모드(PAPER MODE)’를 결성하고 밴드로서의 활동을 모색했으나 곧 대학 입시와 금전적인 문제에 부딪혔다. 충암고등학교 졸업 후 밴드 생활을 이어가기 위해 멤버들은 신촌 근처를 중심으로 활동하며 많은 노력을 하지만 병역 문제로 인해 페이퍼모드는 얼마 못가 데모 테이프만 남기고 해체되었다. 밴드를 떠난 다른 멤버들과 달리 음악을 계속 하기로 결정한 윤상은 페이퍼모드의 데모 테이프를 주변 음악인들에게 들려 주었는데, 이에 흥미를 보인 가수 김현식의 도움으로 데모 테이프에 있던 곡 중 하나인 〈여름밤의 꿈〉이 1988년에 발매된 김현식의 4집에 수록된다. 또 그 데모에는 〈추억 속의 그대〉라는 곡도 포함되어 있었는데, 이 곡은 1988년 황치훈의 데뷔 앨범에 수록되어 타이틀 곡으로 큰 인기를 끌었다. 이 때부터 윤상은 작곡가로서 본격적인 음악 경력을 시작했지만 페이퍼모드에 미련을 버리지 못하고 변진섭의 세션을 하며 기회를 모색하고 있었다. 당시 그는 임재범의 백밴드 ‘외인부대’에 있던 손무현과 절친한 사이였는데 밴드 결성을 위하여 손무현에게 기타리스트 자리를 제안했다. 하지만 손무현은 \"보컬리스트도 없는 상태에서 계속 이렇게 지낼 수 없으니 연습량도 늘릴 겸 월급도 보장되는 김완선의 백밴드를 당분간 같이 해보는 게 어떻겠냐\"며 역으로 설득했고 윤상은 이에 동의했다. 그 후 윤상은 1980년대 후반 인기를 끌던 가수 김완선의 백밴드 ‘실루엣’에서 기타리스트 손무현, 건반연주자 이승호(현재 유명 작사가로 활동), 컴퓨터 변준민과 함께 베이시스트로 1년 가량 활동했다. 작곡가로서의 활동 당시 강수지의 〈보랏빛 향기〉와 김민우의 〈입영열차 안에서〉등이 있다. 특히 윤상은 강수지가 직접 가사를 붙인 〈보랏빛 향기〉, 〈혼자만의 겨울〉 등을 프로듀싱하며 강수지의 성공에 큰 몫을 해냈다.\n",
      "Top-5 passage with score 22.9357\n",
      "중국에 있어서도 “법치” 또는 “의법 행정”(법에 의한 행정)이라는 말이 사용되고 있으나, 이것은 한국이나 일본에서의 “법치주의”와는 다르고, “인치(人治)”, “당치(黨治)”에 대응하는 개념에 불과하다. 중국에 있어서는 전근대적인 “관부무착”(官府無錯, 국가무책임의 법리)이라고 하는 법의식과 사회주의적인 “인민정부와 인민 간의 이익의 대립은 있을 수 없다”고 하는 발상이 행정의 법적 통제나 행정구체의 발전을 지연시키는 요인이 되고 있었다. “치안관리처벌조례”의 시행에 의해, 행정처벌에 대한 불복의 소가 급증하고, 행정사건 전반에 적용되는 통일적인 절차의 정비의 필요성이 인식되었다. 그 결과, “행정소송법”이 제정되었다. 동법은 인민법원의 사법심사의 대상을 “구체적인 행정행위”에 한정하고 있다. 이 행위의 근거규정의 상위법령의 적합성에 대하여는 원칙적으로 사법심사가 미치지 않는다. 재량행위에 있어서는 재량일탈의 유무에 대해서는 사법심사가 미치나, 당부당에 대해서는 미치지 않는다. 다만, 인민법원은 현저하게 공정을 잃은 행정처벌에 대해서는 변경의 판결을 할 수 있다. 행정소송 사건의 인용율은 일본과 비슷하게 낮다. 행정불복심판에 대해서는 “행정복의법(行政復議法)”이 규정한다. 동법 그 자체는 행정불복심사와 행정소송과의 자유선택주의를 채용하고 있으나, 개별 법령에서 행정불복심사 전치를 규정하고 있는 예가 많다. 행정불복심사에는 구체적인 행정행위에 대하여 불복심사에 부대하여, 그 행위의 근거조항에 대한 불복심사도 신청할 수 있다는 것이 특징이다. 행정작용에 수반한 손해보전은 포괄하여 “국가배상”이라고 부른다. 국가배상에는 위법한 행정작용에 기반하여 손해를 전보하는 행정보상(일본에서말하는 국가배상에 해당하나, “작업인원”의 고의과실은 요건이 되지 않는다.)과 적법한 행정작용에 기반하여 손해를 보전하는 행정보상도 규정되어 있다.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "k = 5 \n",
    "\n",
    "for i, q in enumerate(query[:1]):\n",
    "  print(\"[Search query]\\n\", q, \"\\n\")\n",
    "  print(\"[Ground truth passage]\")\n",
    "  print(ground_truth[i], \"\\n\")\n",
    "\n",
    "  r = rank[i]\n",
    "  for j in range(k):\n",
    "    print(\"Top-%d passage with score %.4f\" % (j+1, dot_prod_scores[i][r[j]]))\n",
    "    print(search_corpus[r[j]])\n",
    "  print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XKGyIdQHkn-b"
   },
   "source": [
    "## FAISS를 활용하여 CPU에서 passage retrieval 수행하기\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7PZH2Bu2kx4x"
   },
   "source": [
    "FAISS SQ8, IVF 를 활용해서 cpu에서 passage retrieval 실습해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 94622,
     "status": "ok",
     "timestamp": 1616878585855,
     "user": {
      "displayName": "JinUk Cho",
      "photoUrl": "",
      "userId": "10000090644219567406"
     },
     "user_tz": 420
    },
    "id": "REChmwRnkw5P"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering 960 points in 768D to 16 clusters, redo 1 times, 5 iterations\n",
      "  Preprocessing in 0.00 s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "\n",
    "num_clusters = 16\n",
    "niter = 5\n",
    "k = 5\n",
    "\n",
    "# 1. Clustering\n",
    "emb_dim = p_embs.shape[-1]\n",
    "index_flat = faiss.IndexFlatL2(emb_dim)\n",
    "\n",
    "clus = faiss.Clustering(emb_dim, num_clusters)\n",
    "clus.verbose = True\n",
    "clus.niter = niter\n",
    "clus.train(p_embs, index_flat)\n",
    "centroids = faiss.vector_float_to_array(clus.centroids)\n",
    "centroids = centroids.reshape(num_clusters, emb_dim)\n",
    "\n",
    "quantizer = faiss.IndexFlatL2(emb_dim)\n",
    "quantizer.add(centroids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 94619,
     "status": "ok",
     "timestamp": 1616878585855,
     "user": {
      "displayName": "JinUk Cho",
      "photoUrl": "",
      "userId": "10000090644219567406"
     },
     "user_tz": 420
    },
    "id": "GEiiBQLWkbJv"
   },
   "outputs": [],
   "source": [
    "# 2. SQ8 + IVF indexer (IndexIVFScalarQuantizer)\n",
    "indexer = faiss.IndexIVFScalarQuantizer(quantizer, quantizer.d, quantizer.ntotal, faiss.METRIC_L2)\n",
    "indexer.train(p_embs)\n",
    "indexer.add(p_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 94617,
     "status": "ok",
     "timestamp": 1616878585855,
     "user": {
      "displayName": "JinUk Cho",
      "photoUrl": "",
      "userId": "10000090644219567406"
     },
     "user_tz": 420
    },
    "id": "5tHmCilLnpO7",
    "outputId": "84b5970c-32d4-4e33-9397-6e5b01872238"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.001428365707397461 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# 3. Search using indexer\n",
    "\n",
    "start_time = time.time()\n",
    "D, I = indexer.search(q_embs, k)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 94615,
     "status": "ok",
     "timestamp": 1616878585855,
     "user": {
      "displayName": "JinUk Cho",
      "photoUrl": "",
      "userId": "10000090644219567406"
     },
     "user_tz": 420
    },
    "id": "baaWjLQlponb",
    "outputId": "babf96a6-35c9-44a2-d9c4-9087ea7644ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======[Distance]=======\n",
      "[[127.542694 129.06415  129.45184  130.21706  130.48953 ]\n",
      " [134.16019  137.2977   138.8204   139.31395  139.47934 ]\n",
      " [152.69353  154.42328  154.63792  155.64421  155.67175 ]\n",
      " [133.84999  135.56204  135.80368  136.24295  136.92299 ]\n",
      " [127.75181  129.40057  129.5321   130.41554  130.56493 ]]\n",
      "\n",
      "\n",
      "=======[Index of Top-5 Passages]=======\n",
      "[[112 245 799 158 823]\n",
      " [110 230  15 819 726]\n",
      " [112 245 799 823 158]\n",
      " [112 245 799 158 823]\n",
      " [112 245 799 158 823]]\n"
     ]
    }
   ],
   "source": [
    "print('=======[Distance]=======')\n",
    "print(D)\n",
    "print('\\n')\n",
    "print('=======[Index of Top-5 Passages]=======')\n",
    "print(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 94614,
     "status": "ok",
     "timestamp": 1616878585856,
     "user": {
      "displayName": "JinUk Cho",
      "photoUrl": "",
      "userId": "10000090644219567406"
     },
     "user_tz": 420
    },
    "id": "uGBAAIkWp4me",
    "outputId": "1d0bd267-108a-448e-a3e6-4201666af7dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Search query]\n",
      " 대한민국 제14대 대통령으로 향년 89세를 일기로 서거한 김영삼 대통령의 묘소가 있는 곳은? \n",
      "\n",
      "[Ground truth passage]\n",
      "2015년 11월 10일 건강검진 차 서울대학교 병원을 찾아 17일까지 입원한 뒤 퇴원했다. 그러다, 이틀 뒤인 19일 고열과 혈액감염 의심 증세로 서울대학교 병원에 다시 입원한 후, 11월 21일 오후에 증세가 급격히 악화됨에 따라 중환자실로 옮겨졌다. 상태가 전혀 호전되지 않던 김영삼은 결국 2015년 11월 22일 오전 0시 21분 32초에 병마를 물리치지 못하고 혈액 감염 의심으로 치료를 받던 중 향년 89세의 일기로 서거하였다. 사망에 이른 직접적인 원인은 허약한 전신 상태에 패혈증과 급성 심부전이 겹쳐 일어난 것으로 판단되었다. 장례는 대한민국 최초로 5일간 국가장으로 치뤄졌다. 이는 국장과 국민장이 통합된 이후 처음 치뤄지는 국가장이다. 이어 11월 26일 국회의사당에서 영결식이 있었고 국립서울현충원에 안장되었다. 묘소의 정확한 위치는 제3장군묘역 우측능선에 위치하고 있으며 단독 묘역이다. \n",
      "\n",
      "Top-1 passage with distance 127.5427\n",
      "감리교회는 일찍이 전래 당시 조선의 독립을 위해 노력한 교단이었다. 아펜젤러 선교사는 한국의 독립운동에 깊이 관여하여 독립협회 창설에 도움을 주었으며, 배재학당 출신 이승만을 옥중지원했으며, 3.1독립 선언을 한 33인중 이필주, 신석구 등 감리교인 9명은 장로교인 7명 함께 개신교 대표로 참여했다. 이후 일제 탄압을 받았고, 독립운동에도 직간접적으로 참여하였고, 유관순 열사는 감리교인이었다. 특히 스크랜턴 선교사는 전덕기를 전도하여 서울 숭례문(남대문)에 있던 상동감리교회에서 감리교청년 연합회인 엡웟회와 상동청년학원을 민족의식을 가진 청년들이 모여 을사조약 반대운동을 하였고, 독립 운동의 중추적 역할을 한 \"신민회\"는 감리교회의 지원으로 탄생하였다. 특히 신민회가 조직된 상동감리교회는 이준의 헤이그 특사 파견을 협의하고 실행한 곳으로 유명하다. 또한 사민필지의 저자인 헐버트 선교사는 동대문교회의 담임자로서 수많은 애국자들을 키워냈으며, 고종의 밀사로서 활약했다. 김상옥 의사는 동대문교회 출신이다. 감리교회는 에큐메니칼 운동과 토착화 신학을 강조함으로써 한국적인 상황에서 신학적 토착화에 관심을 기울였으며, 한국 개신교회 활동의 기초를 닦는 역할을 했다. 서울YMCA를 통한 하나님 나라 건설과 지덕체를 건강하게 키워내는 다양한 체육 여가활동을 연합사업으로 성장시켰고, 현재 한국 개신교회 전체가 지키는 추수감사절은 감리교와 장로교 연합공회의(현 한국기독교교회협의회)에서 1921년 11월 둘째 주일 지난 수요일로 정하면서 한국 개신교의 기준이 되었고 부활절 연합예배 및 군선교 등에서 연합활동에 힘썼다.\n",
      "Top-2 passage with distance 129.0641\n",
      "1953년 3월 24일 전라북도 고창군에서 태어난 김이수는 고수국민학교, 광주서중학교, 전남고등학교와 서울대학교 법학과를 졸업했다. 대학교 3학년인 1974년 민청학련 사건에 연루돼 64일간 구금됐다가 석방되었다. 1977년 제19회 사법시험에 합격해 사법연수원 9기를 수료하고 1979년 12월 31일에 사단 군검찰관으로 임관해 5개월 후인 1980년 5월 법무사 군 판사로서 5·18 항쟁 시민군을 태운 버스 운전사에게 사형을 선고했다. 이를 지적하는 새누리당 함진규 의원의 지적에 \"안 맡았으면 좋았을 재판이라고 지금도 생각한다\"며 \"광주 사람으로서 광주항쟁에 참여해야할 입장이었는데 재판을 맡게 됐다. 아주 복잡한 입장이었다\"고 말했으며 \"시민군 가담 여고생에게 징역 1년을 선고하고 50살 농민을 구금하고 징역 2년 집행유예 3년 선고했다. 군의 살상행위를 알린 현직 이장에게 유언비어 유포죄로 징역 1년 집유 2년을 선고했다\"는 새누리당 의원의 지적에는 \"기록을 검토해봐야 한다. 판결문만 보면 모순이 있는 것 같다\"고 했다. 5·16 군사쿠데타에 관해서 \"권력을 잡는 방법은 비정상적이었지만 권력을 잡은 측면과 전체를 한꺼번에 봐야한다\"며 \"10월 유신까지 가는 부분에는 공과가 있다\"고 했다.\n",
      "Top-3 passage with distance 129.4518\n",
      "한편, 히로히토가 유럽으로 떠날 때의 공식 명목은 데라우치 마사타케 내각이 끝나가던 1918년에 일본의 황실을 찾은 코넛과 스트래선 공작 아서 왕자를 답방하는 것이었지만 실질적인 목적은 오랫동안 병상에 있는 다이쇼 천황을 통해 국민들이 품은 황실에 대한 나쁜 여론을 히로히토의 해외여행을 통해 무마하는 것에 있었다. 처음에 황실은 히로히토의 안전을 우려하여 반대했으며, 입헌국민당, 헌정회 등의 의원들, 도야마 미쓰루, 우치다 료헤이 등의 극우계 거물들도 반대했다. 특히 극우파는 출발 전 몇 주 동안 격렬한 항의 시위를 벌였는데 “아버지가 병상에 있을 때 일본을 떠나 여행하는 것은 불효”라는 것이 그 명분이었다. 이에 원로 마쓰카타 마사요시가 데이메이 황후에게 “베르사유 조약 이후의 유럽의 정세를 (조만간 섭정을 맡을) 황태자가 살피는 것은 앞으로를 위해 중요하다”는 내용의 상소문을 올려 황후의 마음을 돌렸고 반대 여론은 차차 수그러들었다. 해외 순방 일정은 다이쇼 천황의 유고에 대비해 최대한 서둘러 실행해야 했다. 때문에 정부와 궁내 관료들은 히로히토가 찾을 나라로 영국, 프랑스, 벨기에, 네덜란드, 바티칸 교황청과 이탈리아로 한정했다. 미국의 워렌 하딩 정부도 히로히토의 방문에 관심을 가졌으나 히로히토와 미국 기자들 사이의 소통 문제를 우려한 워싱턴 D.C.의 주미 일본 대사 시데하라 기주로의 진언으로 미국은 방문 국가에서 제외됐다.\n",
      "Top-4 passage with distance 130.2171\n",
      "1979년에 “중화인민공화국 형법”이 제정되기까지는 단행 법령이나 각종 사법해석, 공산당의 문서 등에 형벌규칙을 두고 있었다. 1979년 형법은 범죄를 “사회에 위해를 가하는 행위로서, 법률에 의한 형벌을 받을 수 있는 것”이라고 정의하여, 유추해석을 공인하고 있다. 1997년에 형법이 전면적으로 개정되었다. 그 이후, 전인대 상무위원회에 의한 다수의 개정이 있다. 1997년 형법은 유추해석을 금지하여, 죄형법정주의를 채택하였다. 한국, 일본을 비롯한 대륙법권의 형법과 비교할 때 큰 특색으로서는, 공범론에 있어서, 정범 · 종범이라고 하는 구성요건을 중심으로 한 구조 대신에, 주범 · 종범이라고 하는 범죄의 경위에 착안한 구조를 이용하고 있다. 주형에는 관제(공안기관의 감독하에 생활하는 것), 구역(노동개조형), 유기징역, 무기징역, 사형의 5종류가 있고, 부가형으로는 벌금, 정치적 권리박탈, 재산 몰수가 있다. 사형에도 집행유예제도가 있는 것이 특징이다.(유예기간이 경과하면, 무기징역으로 감경된다.). 형사소송법도 1996년에 전면적으로 개정되었다. 공안기관에 의한 수사는 입안을 시작으로 증거수집을 거쳐, 인민 검찰원에 기소 의견서를 제출하는 것으로 종료된다. 범죄협의자의 신병 구속기간은 원칙적으로 2개월이나, 소정의 절차를 거쳐 연장할 수 있다. 기소의견서를 수리한 인민검찰원은 공소제기결정, 사건취소결정 또는 불기소결정을 한다. 인민법원은 공소를 수리하면 원칙적으로 1개월~1개월 반 내에 판결한다. 무죄의 추정은 명시적으로 채택되어 있지 않다. 플리 바게닝은 실제로는 행해지나, 제도적으로는 채택되어 있지 않다.\n",
      "Top-5 passage with distance 130.4895\n",
      "부들의 천사관은 성서와 유다이즘과 이교도들의 관념까지 혼합된 것이지만 차츰 천사의 본성은 창조된 영체요, 자유와 지혜를 가지고 창조되었으므로 그중 일부는 타락하여 악마가 되고, 착한 천사는 하느님의 사자요, 인간의 수호자가 되었다고 사유하였다. 고대 말기의 디오니시오(Dionysius Areopagita)는 네오플라토니즘적 도식과 성서에 나오는 천사들의 이름을 이용하여 구품(九品)의 천사 계보를 꾸몄다. 즉 세라핌(熾品), 케루빔(智品), 좌품(座品), 주품(主品), 역품(力品), 능품(能品), 권품(權品), 대천사, 천사의 아홉 등급이다. 물론 이 구품천사론은 그의 신학이자 교회의 교리는 아니다. 천사론에서 가톨릭 신자가 믿어야 할 교리는 꼭 한 가지밖에 없다. 즉 하느님께서 우리 감각의 대상인 세상과 우리의 감각을 초월하는 영의 세계도 창조하셨다는 것이다. 교회는 천사의 존재를 신앙교리로 선언하였다[제4차 라테란 공의회(1215년), Denz. 428, 1차 바티칸 공의회(1870년), Denz. 1783]. 그러나 천사의 본질이 무엇인지, 역할이 무엇인지, 사람마다 수호천사를 가지고 있다느니, 여러 계급으로 구성되어 있다는 등등의 학자의 주장에 대하여 교회는 아무런 유권적 결정도 내린 일이 없다. 다만 교회는 미카엘, 가브리엘, 라파엘 천사의 이름 외에 다른 이름들을(위경에 나오는) 사용하는 것을 금하였고(745년, 라테란 공의회), 삼대(三大) 천사의 축일과(9월 29일) 수호천사의 기념일(10월 2일)을 제정하여 천사공경을 장려하고 있다. (鄭夏權)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, q in enumerate(query[:1]):\n",
    "  print(\"[Search query]\\n\", q, \"\\n\")\n",
    "  print(\"[Ground truth passage]\")\n",
    "  print(ground_truth[i], \"\\n\")\n",
    "\n",
    "  d = D[i]\n",
    "  i = I[i]\n",
    "  for j in range(k):\n",
    "    print(\"Top-%d passage with distance %.4f\" % (j+1, d[j]))\n",
    "    print(search_corpus[i[j]])\n",
    "  print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 94609,
     "status": "ok",
     "timestamp": 1616878585856,
     "user": {
      "displayName": "JinUk Cho",
      "photoUrl": "",
      "userId": "10000090644219567406"
     },
     "user_tz": 420
    },
    "id": "G1SMReLpWsTr"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MRC Practice 6 - Scaling up with FAISS (In-batch)",
   "provenance": [
    {
     "file_id": "1c9Vr7z_LBG2l9K4lVb40pu7Kk22hXQCp",
     "timestamp": 1614240569955
    },
    {
     "file_id": "1Q7iAXm_kwF_NHfOEGdViMCiPHnqoZlXe",
     "timestamp": 1613491158162
    }
   ],
   "toc_visible": true
  },
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
